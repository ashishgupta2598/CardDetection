{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "def main():\n",
    "    # Ensure output directories exist or create them\n",
    "    output_path = '.'  # Replace with args.output_path if using argparse\n",
    "    image_output_path = os.path.join(output_path, \"images\")\n",
    "    mask_output_path = os.path.join(output_path, \"masks\")\n",
    "    os.makedirs(image_output_path, exist_ok=True)\n",
    "    os.makedirs(mask_output_path, exist_ok=True)\n",
    "\n",
    "    input_path = '/home/kabira/Documents/random/midv500_data/midv500'\n",
    "    images = sorted(Path(input_path).rglob(\"*.tif\"))\n",
    "    labels = sorted(Path(input_path).rglob(\"*.json\"))\n",
    "\n",
    "    images_id2path = paths2ids(images)\n",
    "    labels_id2path = paths2ids(labels)\n",
    "\n",
    "    for image_id in tqdm(images_id2path.keys()):\n",
    "        if image_id not in labels_id2path:\n",
    "            continue\n",
    "        image_path = images_id2path[image_id]\n",
    "        label_path = labels_id2path[image_id]\n",
    "\n",
    "        with open(label_path) as f:\n",
    "            label = json.load(f)\n",
    "\n",
    "        if \"quad\" not in label:\n",
    "            continue\n",
    "\n",
    "        image = cv2.imread(str(image_path))\n",
    "\n",
    "        height, width = image.shape[:2]\n",
    "\n",
    "        # Assuming get_mask() is defined elsewhere to generate masks\n",
    "        mask = get_mask(image,(height, width), label)\n",
    "        if  mask is None:\n",
    "            print(\"skipping the frame\",images)\n",
    "            continue\n",
    "\n",
    "        # Save image and mask\n",
    "        cv2.imwrite(os.path.join(image_output_path, f\"{image_id}.jpg\"), image)\n",
    "        cv2.imwrite(os.path.join(mask_output_path, f\"{image_id}.png\"), mask)\n",
    "\n",
    "def paths2ids(paths):\n",
    "    # Example function to create a dictionary of paths to IDs\n",
    "    id2path = {}\n",
    "    for path in paths:\n",
    "        # Assuming IDs are derived from file names or paths\n",
    "        file_name = Path(path).stem  # Get the file name without extension\n",
    "        id2path[file_name] = path\n",
    "    return id2path\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List,Tuple,Dict\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def paths2ids(paths: List[Path]) -> Dict[str, Path]:\n",
    "    return {x.stem: x for x in paths}\n",
    "import numpy as np\n",
    "def get_mask(image,size: Tuple[int, int], label: Dict[str, list]) -> np.ndarray:\n",
    "    # mask = np.zeros(size, dtype=np.uint8)\n",
    "    # print(label)\n",
    "    if \"quad\" in label:\n",
    "        # x_min, y_min, x_max, y_max = label[\"quad\"]\n",
    "        cropped_image = crop_quad(image,label[\"quad\"])\n",
    "        # cv2.rectange(image, (x_min, y_min), (x_max, y_max), (255,), 4)\n",
    "    \n",
    "    return cropped_image\n",
    "\n",
    "\n",
    "def crop_quad(image, quad_coords):\n",
    "    # Convert quad_coords to NumPy array\n",
    "    quad_coords = np.array(quad_coords, dtype=np.int32)\n",
    "    if np.any(quad_coords < 0):\n",
    "        print(\"Ignoring image: Negative coordinates found in quadrilateral.\")\n",
    "        return None\n",
    "    \n",
    "    # Compute bounding box for the quad\n",
    "    x, y, w, h = cv2.boundingRect(quad_coords)\n",
    "    \n",
    "    # Create a mask for the quad\n",
    "    mask = np.zeros_like(image)\n",
    "    cv2.fillPoly(mask, [quad_coords], (255, 255, 255))\n",
    "    \n",
    "    # Bitwise AND between mask and image\n",
    "    masked_image = cv2.bitwise_and(image, mask)\n",
    "    \n",
    "    # Crop the masked image using the bounding box\n",
    "    cropped_image = masked_image[y:y+h, x:x+w]\n",
    "    \n",
    "    return cropped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset descriptption\n",
    "dataset_1 = {\"id\":{},\"passport\":{},\"drivic\":{},\"other_ids\":{}}\n",
    "# train_data = {\"train_data\":{\"id\":{path_of_all},\"passport\":{path_of_all},\"drivic\":{path},\"other_ids\":{}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ensure output directories exist or create them\n",
    "output_path = '.'  # Replace with args.output_path if using argparse\n",
    "image_output_path = os.path.join(output_path, \"images\")\n",
    "mask_output_path = os.path.join(output_path, \"masks\")\n",
    "os.makedirs(image_output_path, exist_ok=True)\n",
    "os.makedirs(mask_output_path, exist_ok=True)\n",
    "\n",
    "input_path = '/home/kabira/Documents/random/midv500_data/midv500'\n",
    "images = sorted(Path(input_path).rglob(\"*.tif\"))\n",
    "labels = sorted(Path(input_path).rglob(\"*.json\"))\n",
    "\n",
    "images_id2path = paths2ids(images)\n",
    "labels_id2path = paths2ids(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15050/15050 [00:01<00:00, 7537.89it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "dataset_1 = {\"id\":[],\"passport\":[],\"drvlic\":[],\"other_ids\":[]}\n",
    "\n",
    "for image_id in tqdm(images_id2path.keys()):\n",
    "    if image_id not in labels_id2path:\n",
    "        continue\n",
    "\n",
    "    image_path = images_id2path[image_id]\n",
    "    label_path = labels_id2path[image_id]\n",
    "\n",
    "    with open(label_path) as f:\n",
    "        label = json.load(f)\n",
    "\n",
    "    if \"quad\" not in label:\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    name = str(image_path).split('/')[-4]\n",
    "    image_path,label_path = str(image_path),str(label_path)\n",
    "    if 'id' in name:\n",
    "        dataset_1['id'].append([image_path,label_path])\n",
    "    elif 'passport' in name:\n",
    "        dataset_1['passport'].append([image_path,label_path])\n",
    "    elif 'drvlic' in name:\n",
    "        dataset_1['drvlic'].append([image_path,label_path])\n",
    "    else:\n",
    "        dataset_1['other_ids'].append([image_path,label_path])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating train,val and test file for all the model versions\n",
    "\n",
    "#taking train==70%, val=15%,test=15%\n",
    "train_p = 0.7\n",
    "val_p = 0.15\n",
    "test_p = 0.15\n",
    "\n",
    "dataset_train = {\"id\":[],\"passport\":[],\"drvlic\":[],\"other_ids\":[]}\n",
    "\n",
    "dataset_val = {\"id\":[],\"passport\":[],\"drvlic\":[],\"other_ids\":[]}\n",
    "\n",
    "dataset_test = {\"id\":[],\"passport\":[],\"drvlic\":[],\"other_ids\":[]}\n",
    "\n",
    "for card_name,val in dataset_1.items():\n",
    "    lenth = len(dataset_1[card_name])\n",
    "    values = dataset_1[card_name]\n",
    "    \n",
    "    train_length = int(lenth*train_p)\n",
    "    val_length = int(lenth*val_p)\n",
    "    test_length = int(lenth*test_p)\n",
    "\n",
    "    dataset_train[card_name] = values[0:train_length]\n",
    "    dataset_val[card_name] = values[train_length:val_length+train_length]\n",
    "    dataset_test[card_name] = values[train_length+val_length:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 15:44:03.746800: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-25 15:44:04.763212: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.16.1'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved to dataset_all.json\n"
     ]
    }
   ],
   "source": [
    "# Save dataset_1 as JSON'\n",
    "final_dataset = {\"train\":dataset_train,\"val\":dataset_val,\"test\":dataset_test}\n",
    "json_filename = 'dataset_all.json'\n",
    "with open(json_filename, 'w') as json_file:\n",
    "    json.dump(final_dataset, json_file, indent=4)\n",
    "\n",
    "print(f\"Dataset saved to {json_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "5700\n",
      "passport\n",
      "4800\n",
      "drvlic\n",
      "3600\n",
      "other_ids\n",
      "900\n"
     ]
    }
   ],
   "source": [
    "for card_name,val in dataset_1.items():\n",
    "    print(card_name)\n",
    "    print(len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "3989\n",
      "passport\n",
      "3360\n",
      "drvlic\n",
      "2520\n",
      "other_ids\n",
      "630\n"
     ]
    }
   ],
   "source": [
    "for card_name,val in dataset_train.items():\n",
    "    print(card_name)\n",
    "    print(len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "855\n",
      "passport\n",
      "720\n",
      "drvlic\n",
      "540\n",
      "other_ids\n",
      "135\n"
     ]
    }
   ],
   "source": [
    "for card_name,val in dataset_val.items():\n",
    "    print(card_name)\n",
    "    print(len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "856\n",
      "passport\n",
      "720\n",
      "drvlic\n",
      "540\n",
      "other_ids\n",
      "135\n"
     ]
    }
   ],
   "source": [
    "for card_name,val in dataset_test.items():\n",
    "    print(card_name)\n",
    "    print(len(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#50 DIifferent identity types docs\n",
    "#17 different ID cards—-> ID DESIGNATION(CHECKED)...18 \n",
    "#14 types of passport—> 10 passports in train,2 in test,2val(14 done)\n",
    "#13 Driving liceses —> Same with DL(12 COMING)\n",
    "#6 other ID of various countries….NOT WITH ID_DEsignatiojn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_1['other_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# json_filename = 'dataset_all.json'\n",
    "# with open(json_filename,'r') as json_file:\n",
    "#     data = json.loads(json_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_mask(size: Tuple[int, int], label: dict) -> np.ndarray:\n",
    "    mask = np.zeros(size)\n",
    "    poly = np.array(label[\"quad\"])\n",
    "    return cv2.fillPoly(mask, [poly], (255,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "def main(data,output_path):\n",
    "    # Ensure output directories exist or create them\n",
    "    #output_path = '../../train'  # Replace with args.output_path if using argparse\n",
    "    image_output_path = os.path.join(output_path, \"images\")\n",
    "    mask_output_path = os.path.join(output_path, \"masks\")\n",
    "    os.makedirs(image_output_path, exist_ok=True)\n",
    "    os.makedirs(mask_output_path, exist_ok=True)\n",
    "    \n",
    "    for key in data.keys():\n",
    "        for i  in tqdm(range(len(data[key]))):\n",
    "            # print(data[key][i])\n",
    "            image_path = data[key][i][0]#images_id2path[image_id]\n",
    "            label_path = data[key][i][1]#labels_id2path[image_id]\n",
    "\n",
    "            with open(label_path) as f:\n",
    "                label = json.load(f)\n",
    "                \n",
    "\n",
    "            if \"quad\" not in label:\n",
    "                continue\n",
    "            \n",
    "            pp =  np.array(label[\"quad\"])\n",
    "            if len(pp[pp< 0]):\n",
    "                continue\n",
    "            image = cv2.imread(str(image_path))\n",
    "\n",
    "            height, width = image.shape[:2]\n",
    "\n",
    "            # Assuming get_mask() is defined elsewhere to generate masks\n",
    "            mask = get_mask((height, width), label)\n",
    "            if  mask is None:\n",
    "                print(\"skipping the frame\",images)\n",
    "                continue\n",
    "\n",
    "            # Save image and mask\n",
    "            # save_pth = '{key}_{int}.jpg'.format(_\n",
    "            cv2.imwrite(os.path.join(image_output_path, f\"{key}_{i}.jpg\"), image)\n",
    "            cv2.imwrite(os.path.join(mask_output_path, f\"{key}_{i}.png\"), mask)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n",
    "# main(dataset_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 855/855 [00:21<00:00, 39.24it/s] \n",
      "100%|██████████| 720/720 [00:18<00:00, 39.71it/s] \n",
      "100%|██████████| 540/540 [00:12<00:00, 41.57it/s] \n",
      "100%|██████████| 135/135 [00:03<00:00, 33.75it/s]\n"
     ]
    }
   ],
   "source": [
    "main(dataset_val,'../../val')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 855/855 [00:17<00:00, 49.56it/s] \n",
      "100%|██████████| 720/720 [00:15<00:00, 46.91it/s] \n",
      "100%|██████████| 540/540 [00:12<00:00, 44.69it/s] \n",
      "100%|██████████| 135/135 [00:03<00:00, 36.87it/s]\n"
     ]
    }
   ],
   "source": [
    "main(dataset_val,'../../test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dataset_train['id'][0][1]) as f:\n",
    "    label = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(label['quad']).all()<0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.any(np.array(label['quad']))<0:\n",
    "    print(\"yoo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-12, 672], [904, 643], [931, 1142], [122, 1185]]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label['quad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pk']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../../train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'passport', 'drvlic', 'other_ids'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset_train\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset_train' is not defined"
     ]
    }
   ],
   "source": [
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'list' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28many\u001b[39m(number \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m number \u001b[38;5;129;01min\u001b[39;00m label[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquad\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn[63], line 1\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28many\u001b[39m(number \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m number \u001b[38;5;129;01min\u001b[39;00m label[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquad\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'list' and 'int'"
     ]
    }
   ],
   "source": [
    "any(number < 0 for number in label['quad'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ala\n"
     ]
    }
   ],
   "source": [
    "pp = np.array(label['quad'])\n",
    "if len(pp[pp< 0]):\n",
    "    print(\"ala\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
